{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#########################################################################################################\n",
    "# Training data for the 8 categories                                                                    #\n",
    "#categories = ['comp.graphics','comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
    "#              'comp.sys.mac.hardware','rec.autos', 'rec.motorcycles',\n",
    "#              'rec.sport.baseball', 'rec.sport.hockey']\n",
    "categories = ['comp.graphics','comp.os.ms-windows.misc']\n",
    "\n",
    "###################################### How to run code start ############################################\n",
    "# Step 1:  Pass at max 2 or 3 categories in the above step as it will take a long time to run\n",
    "# Step 2: Based on scenario uncomment code and run grid search\n",
    "# Step 3 : Ensure to pass the correct dataset to gridsearch\n",
    "# Example for step 3 : grid.fit(newsgroups_trainwithoutheaders.data, newsgroups_trainwithoutheaders.target)\n",
    "###################################### How to run code end  #############################################\n",
    "\n",
    "# The below code is to determine the accuracy on train data by removing headers and footers             #\n",
    "newsgroups_trainwithoutheaders = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers'),\n",
    "                                     categories=categories)\n",
    "#newsgroups_trainheaders = fetch_20newsgroups(subset='test',\n",
    "#                                     remove=('headers', 'footers'),\n",
    "#                                     categories=categories)\n",
    "\n",
    "# The below code is to determine the accuracy on train data by NOT removing headers,footers and quotes  #\n",
    "#newsgroups_testwithoutheaders = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories)\n",
    "#newsgroups_testwithoutheaders = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories)\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "# The below code is to check if Lemmatizer can be used for feature extraction\n",
    "# Assign Lemmatizer to Count Vectorizer [http://scikit-learn.org/stable/modules/feature_extraction.html]#\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "analyzer=CountVectorizer().build_analyzer()\n",
    "import re\n",
    "pattern = re.compile(\"[+-]?\\d+(?:\\.\\d+)?$\")\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "    \n",
    "def lemmatize_sent(list_word):\n",
    "    return [wnl.lemmatize(word.lower(),pos=penn2morphy(tag)) \n",
    "           for word, tag in pos_tag(list_word)]\n",
    "\n",
    "def lem_rmv_digit(doc):\n",
    "    word = [word for word in lemmatize_sent(analyzer(doc))]\n",
    "    return (filter(lambda x: not pattern.match(x),word))\n",
    "   \n",
    "count_vect = CountVectorizer(min_df=3, stop_words=\"english\",analyzer=lem_rmv_digit)\n",
    "\n",
    "#########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  \"Subject: What's up in Rochester???\\n\"\n",
      "  'Reply-To: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  'Organization: University of Rochester Hockey Science Dept.\\n'\n",
      "  'Distribution: na\\n'\n",
      "  'Lines: 25\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  \"Here we are with the Sabres up 2-0 to the Bruins and the Sabres' farm\\n\"\n",
      "  'team, the Rochester Amerks, on their way to the Calder Cup (urp!) and\\n'\n",
      "  'what kind of hockey coverage are we getting? The same Penguins/Devils\\n'\n",
      "  \"every other day crap that everyone else gets. What's worse, the\\n\"\n",
      "  'SportsChannel coverage of the Islanders appears to be blocked out,\\n'\n",
      "  'since we got CBA basketball last night, if you can ..., \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <530x3909 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 43551 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x3909 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 43551 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x4088 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 45592 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x4088 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45592 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x4209 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 44968 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x4209 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 44968 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  \"Subject: What's up in Rochester???\\n\"\n",
      "  'Reply-To: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  'Organization: University of Rochester Hockey Science Dept.\\n'\n",
      "  'Distribution: na\\n'\n",
      "  'Lines: 25\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  \"Here we are with the Sabres up 2-0 to the Bruins and the Sabres' farm\\n\"\n",
      "  'team, the Rochester Amerks, on their way to the Calder Cup (urp!) and\\n'\n",
      "  'what kind of hockey coverage are we getting? The same Penguins/Devils\\n'\n",
      "  \"every other day crap that everyone else gets. What's worse, the\\n\"\n",
      "  'SportsChannel coverage of the Islanders appears to be blocked out,\\n'\n",
      "  'since we got CBA basketball last night, if you can ..., \n",
      "array([1, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <530x2319 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 38153 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x2319 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38153 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x2380 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 39855 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2380 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39855 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x2378 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 38806 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2378 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38806 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  \"Subject: What's up in Rochester???\\n\"\n",
      "  'Reply-To: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  'Organization: University of Rochester Hockey Science Dept.\\n'\n",
      "  'Distribution: na\\n'\n",
      "  'Lines: 25\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  \"Here we are with the Sabres up 2-0 to the Bruins and the Sabres' farm\\n\"\n",
      "  'team, the Rochester Amerks, on their way to the Calder Cup (urp!) and\\n'\n",
      "  'what kind of hockey coverage are we getting? The same Penguins/Devils\\n'\n",
      "  \"every other day crap that everyone else gets. What's worse, the\\n\"\n",
      "  'SportsChannel coverage of the Islanders appears to be blocked out,\\n'\n",
      "  'since we got CBA basketball last night, if you can ..., \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 9.0s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <530x3444 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 60793 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x3444 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60793 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 9.5s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x3616 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 63451 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x3616 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 63451 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 8.6s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x3590 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 60725 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x3590 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60725 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  \"Subject: What's up in Rochester???\\n\"\n",
      "  'Reply-To: ferguson@cs.rochester.edu (George Ferguson)\\n'\n",
      "  'Organization: University of Rochester Hockey Science Dept.\\n'\n",
      "  'Distribution: na\\n'\n",
      "  'Lines: 25\\n'\n",
      "  '\\n'\n",
      "  '\\n'\n",
      "  \"Here we are with the Sabres up 2-0 to the Bruins and the Sabres' farm\\n\"\n",
      "  'team, the Rochester Amerks, on their way to the Calder Cup (urp!) and\\n'\n",
      "  'what kind of hockey coverage are we getting? The same Penguins/Devils\\n'\n",
      "  \"every other day crap that everyone else gets. What's worse, the\\n\"\n",
      "  'SportsChannel coverage of the Islanders appears to be blocked out,\\n'\n",
      "  'since we got CBA basketball last night, if you can ..., \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 8.3s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <530x2202 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 56588 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x2202 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56588 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 8.0s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x2274 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 58940 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2274 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 58940 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 0], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 7.8s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <531x2237 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 56158 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2237 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56158 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x3909 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 43551 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.1s, 0.0min\n",
      "[Memory]    0.1s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x4088 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45592 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x4209 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 44968 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x2319 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38153 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2380 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39855 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2378 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38806 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x3444 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60793 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x3616 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 63451 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x3590 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60725 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <530x2202 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56588 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2274 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 58940 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <531x2237 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56158 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x3909 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 43551 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x4088 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45592 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.2s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x4209 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 44968 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x2319 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38153 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2380 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39855 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.2s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2378 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38806 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x3444 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60793 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x3616 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 63451 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x3590 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60725 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x2202 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56588 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2274 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 58940 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2237 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56158 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.2s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x3909 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 43551 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 4.1s, 0.1min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x4088 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45592 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x4209 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 44968 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 3.1s, 0.1min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x2319 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38153 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.5s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2380 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39855 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2378 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 38806 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.7s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x3444 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60793 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 3.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x3616 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 63451 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 3.0s, 0.1min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x3590 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 60725 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 3.9s, 0.1min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <530x2202 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56588 stored elements in Compressed Sparse Row format>, \n",
      "array([1, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2274 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 58940 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.9s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=50, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "None, <531x2237 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 56158 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 0], dtype=int64))\n",
      "________________________________________________fit_transform_one - 2.1s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\108e8aff371e27d87736b2ec0042e98d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f7d099505b68ecc7eeaeced12c6bd87\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0521d20a3e09404023fd9fa4627821f2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\692fd22fb034977f5e90472c6a40f18d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c1a32c97a527764ff1a7e5f7508e827c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\080a83b9f82f33cc4847af58e9e2bf95\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\31eb8c04331bbaafa039c7e2972e05cf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7ec3885a1b75f48d66aaee4b75540181\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a198cb8b9e2e02ca313a8025fc270233\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0a6c2aa8e109d2bc47e08f213c2ed833\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\676e97281495abc6504b002062e4180c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a0726489c3a2d097a4d694915f67a6e0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\1f169548bf4af7aa01095869669ad295\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f63166dd14d7a9c7e69c1839459b70da\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8e36c6cba3597239864fc9b586baf5c9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\bcc0ec5a59297bb10696dfc5f7cb5296\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9d035974f5d876129937d91847f216ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4c0f0f30aa8a66880c307ea9289f2bd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\57d2e910a4b41120ebedcfa59b140b9d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f68adeae510a7575250ab37a953abb13\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8c00ce1713611e2faab029a98e4aa615\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\96b51d38efbd6f442228cdebc9f943ac\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b17855d4948b5cb46eae621786cb1964\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fbd3fe1d8b0ad9dc448562df4514a931\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a16a315ddae99fcf956595ead5cb796a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\682bb86a95946d30d24776a706ddd2e1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6ce2ff0ba69a80acaf5ed76980b7fd7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a954406d98619a4296119078220f86ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b26a5a3e47a3f3560a4ed168887e09f8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9fa5254aab811397fc76b999d5ac58c6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7c023f726b61045fa72d44930b58d0d7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\381b7d27e5c4d3e4c2df930e52a175ee\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\01e0f4c54d8cfb4df02cd6a58294f9f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\cb4621fee35492e16c454ca20430054a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b8815c1fd7b4d89ee3549c78a1825f94\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\564ad9426292386b4e4fcdd4cc2509af\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c12ddbc08c2d81f16393ebeb5188af68\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6fdbc8cc50b6d44533987e80568112de\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3314053a8129b03e28877a2d5c38a65d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b338961a54245f868f5a15737a509147\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3e0de9155d02b590d7e6d5ea6c9ecaf6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\aaa72da9aebb2067145cbd9f5ead049e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03ba494cce87c70079e72c99d35f2292\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b80edddac002f5f953f09f5f254c70dc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.1s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\08472f96e8a607f1b0b2d1e982e797a0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\26a2f426dae0f178b68c8b78166156b8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\824d04414ec0b029b7bcf2fb45be78bd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c4966319ff6c3295f22656a968d34996\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\108e8aff371e27d87736b2ec0042e98d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f7d099505b68ecc7eeaeced12c6bd87\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0521d20a3e09404023fd9fa4627821f2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\692fd22fb034977f5e90472c6a40f18d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c1a32c97a527764ff1a7e5f7508e827c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\080a83b9f82f33cc4847af58e9e2bf95\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\31eb8c04331bbaafa039c7e2972e05cf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7ec3885a1b75f48d66aaee4b75540181\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a198cb8b9e2e02ca313a8025fc270233\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0a6c2aa8e109d2bc47e08f213c2ed833\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\676e97281495abc6504b002062e4180c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a0726489c3a2d097a4d694915f67a6e0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\1f169548bf4af7aa01095869669ad295\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f63166dd14d7a9c7e69c1839459b70da\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8e36c6cba3597239864fc9b586baf5c9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\bcc0ec5a59297bb10696dfc5f7cb5296\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9d035974f5d876129937d91847f216ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4c0f0f30aa8a66880c307ea9289f2bd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\57d2e910a4b41120ebedcfa59b140b9d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f68adeae510a7575250ab37a953abb13\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8c00ce1713611e2faab029a98e4aa615\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\96b51d38efbd6f442228cdebc9f943ac\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b17855d4948b5cb46eae621786cb1964\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fbd3fe1d8b0ad9dc448562df4514a931\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a16a315ddae99fcf956595ead5cb796a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\682bb86a95946d30d24776a706ddd2e1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6ce2ff0ba69a80acaf5ed76980b7fd7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a954406d98619a4296119078220f86ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b26a5a3e47a3f3560a4ed168887e09f8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9fa5254aab811397fc76b999d5ac58c6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7c023f726b61045fa72d44930b58d0d7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\381b7d27e5c4d3e4c2df930e52a175ee\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\01e0f4c54d8cfb4df02cd6a58294f9f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\cb4621fee35492e16c454ca20430054a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b8815c1fd7b4d89ee3549c78a1825f94\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\564ad9426292386b4e4fcdd4cc2509af\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c12ddbc08c2d81f16393ebeb5188af68\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6fdbc8cc50b6d44533987e80568112de\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3314053a8129b03e28877a2d5c38a65d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b338961a54245f868f5a15737a509147\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3e0de9155d02b590d7e6d5ea6c9ecaf6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\aaa72da9aebb2067145cbd9f5ead049e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03ba494cce87c70079e72c99d35f2292\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b80edddac002f5f953f09f5f254c70dc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\08472f96e8a607f1b0b2d1e982e797a0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\26a2f426dae0f178b68c8b78166156b8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\824d04414ec0b029b7bcf2fb45be78bd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c4966319ff6c3295f22656a968d34996\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\108e8aff371e27d87736b2ec0042e98d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f7d099505b68ecc7eeaeced12c6bd87\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0521d20a3e09404023fd9fa4627821f2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\692fd22fb034977f5e90472c6a40f18d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c1a32c97a527764ff1a7e5f7508e827c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\080a83b9f82f33cc4847af58e9e2bf95\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\31eb8c04331bbaafa039c7e2972e05cf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7ec3885a1b75f48d66aaee4b75540181\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a198cb8b9e2e02ca313a8025fc270233\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\0a6c2aa8e109d2bc47e08f213c2ed833\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\676e97281495abc6504b002062e4180c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a0726489c3a2d097a4d694915f67a6e0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\1f169548bf4af7aa01095869669ad295\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f63166dd14d7a9c7e69c1839459b70da\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8e36c6cba3597239864fc9b586baf5c9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\bcc0ec5a59297bb10696dfc5f7cb5296\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9d035974f5d876129937d91847f216ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4c0f0f30aa8a66880c307ea9289f2bd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\57d2e910a4b41120ebedcfa59b140b9d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f68adeae510a7575250ab37a953abb13\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8c00ce1713611e2faab029a98e4aa615\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\96b51d38efbd6f442228cdebc9f943ac\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b17855d4948b5cb46eae621786cb1964\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fbd3fe1d8b0ad9dc448562df4514a931\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a16a315ddae99fcf956595ead5cb796a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\682bb86a95946d30d24776a706ddd2e1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6ce2ff0ba69a80acaf5ed76980b7fd7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a954406d98619a4296119078220f86ab\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b26a5a3e47a3f3560a4ed168887e09f8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9fa5254aab811397fc76b999d5ac58c6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7c023f726b61045fa72d44930b58d0d7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\381b7d27e5c4d3e4c2df930e52a175ee\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\01e0f4c54d8cfb4df02cd6a58294f9f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\cb4621fee35492e16c454ca20430054a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b8815c1fd7b4d89ee3549c78a1825f94\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\564ad9426292386b4e4fcdd4cc2509af\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9e1aaa1f43ed3ee3d2dd6d27a12e5342\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\517e18070e423d4fe7f536dc22121529\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c12ddbc08c2d81f16393ebeb5188af68\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\8266d64d3e81d577da1fe8657c85036d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\abbe5ec70f8920037ec9fc4b87d0801c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6fdbc8cc50b6d44533987e80568112de\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7f3376f0ff58277f896d0545d8440d9e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ee4b8c3405aabcbee8e31f16e611c703\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3314053a8129b03e28877a2d5c38a65d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5549b38dd6b88109bebdf2528db86695\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fe462dbac0712a0bb6bb08741a277388\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b338961a54245f868f5a15737a509147\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03d523934ede9d076eb2cd69f41c10ba\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\fcf20a8ace0687f0b70e81eb8dd099a4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3e0de9155d02b590d7e6d5ea6c9ecaf6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b52e600e343a88e8867077a7ced44903\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\36d058230f04d5523db98139ee09d429\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\aaa72da9aebb2067145cbd9f5ead049e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\66c9b470b74b5f45068cc5936670d37b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a1937cc5cdcd56b3a304c7e06742b725\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\03ba494cce87c70079e72c99d35f2292\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\7860e71abcba7172486c1af962fe0aa9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\4796c30779583812d601648c47209e42\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b80edddac002f5f953f09f5f254c70dc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\ad8c2540c51ae61facb8c71bbcd46d36\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6949539987189486dc3097454e5e0a0b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\08472f96e8a607f1b0b2d1e982e797a0\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\096c0afa7f240b78f81d960016347821\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\e6dcdbb734a3fd3a503e41d0dd3b9ecd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\26a2f426dae0f178b68c8b78166156b8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43bb13b9bf8912f7ae416cac77710fed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\a403d75b538873e1d5edc3bbf2c15851\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\824d04414ec0b029b7bcf2fb45be78bd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\5ff567dfe1cca325be338fe89ae7b073\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\feb000bc1f64cc6fed85d066263598c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]    0.0s, 0.0min: Loading _fit_transform_one from C:\\Users\\MADHU~1.KOL\\AppData\\Local\\Temp\\tmpygvedhna\\joblib\\sklearn\\pipeline\\_fit_transform_one\\c4966319ff6c3295f22656a968d34996\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function lem_rmv_digit at 0x000001DCD144B9D8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words='english', strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "None, [ 'From: luriem@alleg.edu(Michael Lurie) The Liberalizer\\n'\n",
      "  'Subject: Re: 200 SBs & 200 HRs\\n'\n",
      "  'Organization: Allegheny College\\n'\n",
      "  'Lines: 18\\n'\n",
      "  '\\n'\n",
      "  'In article <C5ws3K.HqC@odin.corp.sgi.com> dans@fore.csd.sgi.com (Dan  \\n'\n",
      "  'Steinman) writes:\\n'\n",
      "  '> Last night on the Giants/Mets radio broadcast Hank and Ted were  \\n'\n",
      "  'discussing the fact that there were only 16 players who had ever hit 200  \\n'\n",
      "  'homeruns and stolen 200 bases in their career (while HoJo was batting).   \\n'\n",
      "  'Anyone have a list?  Not as easy as it sounds to come up with all of '\n",
      "  'them.   \\n'\n",
      "  \"I couldn't.  Mays, Mantle, Aaron, Henderson, Morgan, Bonds (Dad), ???   \\n\"\n",
      "  \"Frank Robinson?  Molitor?  Yount? ..., \n",
      "array([0, ..., 1], dtype=int64))\n",
      "_______________________________________________fit_transform_one - 12.2s, 0.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), None, <796x4655 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 95184 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "None, <796x4655 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 95184 stored elements in Compressed Sparse Row format>, \n",
      "array([0, ..., 1], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# used to cache results\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "# print(__doc__)\n",
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "\n",
    "#########################################################################################################\n",
    "#Construct Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')), # Feature Extraction\n",
    "    ('tfidf', TfidfTransformer()),                             # Feature Extraction \n",
    "    ('reduce_dim', TruncatedSVD(random_state=0)),              # Dimensionality Reduction    \n",
    "    ('clf', GaussianNB()),                                     # Classifier \n",
    "], \n",
    "memory=memory\n",
    ")\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "# Feature Extraction : Min Df values for CountVectorizer                                                #\n",
    "T_OPTIONS = [3,5]\n",
    "# Feature Extraction : for Lemmatization                                                                #\n",
    "N_FEATURES_OPTIONS = [10, 50]\n",
    "# Classifer : Best Gamma Value                                                                          #\n",
    "C_OPTIONS = [1000]\n",
    "# Classifer : Regularization Strengths  for regression#\n",
    "REG_OPTIONS = [{'penalty': ['l1']},{'penalty': ['l2']}]\n",
    "REG_STRENGTH_OPTIONS = [10,100]\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "# Set up the parameter grid                                                                             #\n",
    "param_grid = [\n",
    "    {\n",
    "        'vect__min_df': T_OPTIONS,\n",
    "       'vect__analyzer' : ['word',lem_rmv_digit],\n",
    "        'reduce_dim': [TruncatedSVD(), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'clf': [LinearSVC()],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'vect__min_df': T_OPTIONS,\n",
    "        'vect__analyzer' : ['word',lem_rmv_digit],\n",
    "        'reduce_dim': [TruncatedSVD(), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'clf': [LogisticRegression()],\n",
    "        'clf__C': REG_OPTIONS,\n",
    "        'clf__C': REG_STRENGTH_OPTIONS\n",
    "    },    \n",
    "    {\n",
    "        'vect__min_df': T_OPTIONS,\n",
    "        'vect__analyzer' : ['word',lem_rmv_digit],\n",
    "        'reduce_dim': [TruncatedSVD(), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'clf': [GaussianNB()],\n",
    "    },\n",
    "]\n",
    "#########################################################################################################\n",
    "\n",
    "grid = GridSearchCV(pipeline, cv=3, n_jobs=1, param_grid=param_grid, scoring='accuracy')\n",
    "grid.fit(newsgroups_trainwithoutheaders.data, newsgroups_trainwithoutheaders.target)\n",
    "rmtree(cachedir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madhu.kolli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\madhu.kolli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\madhu.kolli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\madhu.kolli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\madhu.kolli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>param_vect__analyzer</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.597575</td>\n",
       "      <td>0.069352</td>\n",
       "      <td>0.928392</td>\n",
       "      <td>0.937808</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.956685</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.928437</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.013348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.626285</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>0.900754</td>\n",
       "      <td>0.917071</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.879245</td>\n",
       "      <td>0.924670</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.041220</td>\n",
       "      <td>0.016365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.295043</td>\n",
       "      <td>4.570321</td>\n",
       "      <td>0.915829</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913534</td>\n",
       "      <td>0.941509</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.900188</td>\n",
       "      <td>0.393938</td>\n",
       "      <td>0.554896</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.019965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.286953</td>\n",
       "      <td>4.761483</td>\n",
       "      <td>0.896985</td>\n",
       "      <td>0.900769</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.851224</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.219834</td>\n",
       "      <td>0.993047</td>\n",
       "      <td>0.048154</td>\n",
       "      <td>0.035043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.376099</td>\n",
       "      <td>0.082049</td>\n",
       "      <td>0.958543</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>0.024337</td>\n",
       "      <td>0.032748</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.198426</td>\n",
       "      <td>0.063370</td>\n",
       "      <td>0.958543</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.256382</td>\n",
       "      <td>4.112712</td>\n",
       "      <td>0.958543</td>\n",
       "      <td>0.994343</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.174841</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.004622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.217856</td>\n",
       "      <td>4.202346</td>\n",
       "      <td>0.958543</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.981168</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.169242</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.007584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.492947</td>\n",
       "      <td>0.059679</td>\n",
       "      <td>0.878141</td>\n",
       "      <td>0.884443</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.916981</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.838041</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.155257</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.039316</td>\n",
       "      <td>0.033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.428101</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.893230</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.883019</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.871940</td>\n",
       "      <td>0.071626</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.833805</td>\n",
       "      <td>4.401734</td>\n",
       "      <td>0.854271</td>\n",
       "      <td>0.872482</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.871698</td>\n",
       "      <td>0.919021</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.109942</td>\n",
       "      <td>0.129658</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.035095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.515058</td>\n",
       "      <td>4.027507</td>\n",
       "      <td>0.836683</td>\n",
       "      <td>0.846734</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845865</td>\n",
       "      <td>0.847170</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.783427</td>\n",
       "      <td>0.090366</td>\n",
       "      <td>0.149148</td>\n",
       "      <td>0.036003</td>\n",
       "      <td>0.051512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.302305</td>\n",
       "      <td>0.076215</td>\n",
       "      <td>0.951005</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951128</td>\n",
       "      <td>0.979245</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.979284</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.964218</td>\n",
       "      <td>0.854412</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.007093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.648962</td>\n",
       "      <td>0.073021</td>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.972993</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.975518</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.261044</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.513599</td>\n",
       "      <td>3.891695</td>\n",
       "      <td>0.951005</td>\n",
       "      <td>0.970476</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.967925</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.975518</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>0.967985</td>\n",
       "      <td>0.420537</td>\n",
       "      <td>0.078187</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.558616</td>\n",
       "      <td>3.896018</td>\n",
       "      <td>0.909548</td>\n",
       "      <td>0.941591</td>\n",
       "      <td>LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)</td>\n",
       "      <td>1000</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.962335</td>\n",
       "      <td>0.366181</td>\n",
       "      <td>0.013827</td>\n",
       "      <td>0.029748</td>\n",
       "      <td>0.024151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.098582</td>\n",
       "      <td>0.057348</td>\n",
       "      <td>0.942211</td>\n",
       "      <td>0.947236</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.952919</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.079571</td>\n",
       "      <td>0.053506</td>\n",
       "      <td>0.938442</td>\n",
       "      <td>0.945353</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.951036</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.937853</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.005533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.904082</td>\n",
       "      <td>0.927136</td>\n",
       "      <td>0.929657</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.201066</td>\n",
       "      <td>0.017475</td>\n",
       "      <td>0.018189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.069392</td>\n",
       "      <td>3.867975</td>\n",
       "      <td>0.922111</td>\n",
       "      <td>0.935933</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.941509</td>\n",
       "      <td>0.901887</td>\n",
       "      <td>0.935970</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.930320</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.083538</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0.004568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.107295</td>\n",
       "      <td>0.056806</td>\n",
       "      <td>0.967337</td>\n",
       "      <td>0.979901</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951128</td>\n",
       "      <td>0.983019</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.979284</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.002335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.090519</td>\n",
       "      <td>0.057491</td>\n",
       "      <td>0.969849</td>\n",
       "      <td>0.979273</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.979284</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.087903</td>\n",
       "      <td>3.926058</td>\n",
       "      <td>0.967337</td>\n",
       "      <td>0.981785</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.983019</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.151158</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.079876</td>\n",
       "      <td>3.826979</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.981158</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981168</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.977401</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.107791</td>\n",
       "      <td>0.062165</td>\n",
       "      <td>0.900754</td>\n",
       "      <td>0.910819</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.900188</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.027759</td>\n",
       "      <td>0.016383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.081719</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.894482</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890977</td>\n",
       "      <td>0.909434</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.894539</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.012232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.088081</td>\n",
       "      <td>4.009394</td>\n",
       "      <td>0.850503</td>\n",
       "      <td>0.852397</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.826415</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.110744</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>0.031931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.075872</td>\n",
       "      <td>3.975829</td>\n",
       "      <td>0.845477</td>\n",
       "      <td>0.848001</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860902</td>\n",
       "      <td>0.866038</td>\n",
       "      <td>0.871698</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.803774</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.119753</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.041232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.129847</td>\n",
       "      <td>0.111797</td>\n",
       "      <td>0.942211</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.922787</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.012497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.091746</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.942211</td>\n",
       "      <td>0.939697</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>10</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.937736</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.945386</td>\n",
       "      <td>0.947170</td>\n",
       "      <td>0.935970</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.085080</td>\n",
       "      <td>4.063243</td>\n",
       "      <td>0.932161</td>\n",
       "      <td>0.930286</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.902072</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.166909</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>0.019964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.069050</td>\n",
       "      <td>4.047359</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.939078</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913534</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.935970</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.930320</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.259064</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.008701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.102876</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>0.967337</td>\n",
       "      <td>0.986182</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958647</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.012412</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.968593</td>\n",
       "      <td>0.990577</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958647</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.990584</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.097791</td>\n",
       "      <td>3.981878</td>\n",
       "      <td>0.971106</td>\n",
       "      <td>0.989951</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.986817</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.990584</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.083380</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.076161</td>\n",
       "      <td>4.065263</td>\n",
       "      <td>0.967337</td>\n",
       "      <td>0.988068</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958647</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.984934</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.986817</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.096262</td>\n",
       "      <td>0.060995</td>\n",
       "      <td>0.898241</td>\n",
       "      <td>0.918353</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.935849</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.012372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.069687</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.015352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.096927</td>\n",
       "      <td>4.171902</td>\n",
       "      <td>0.875628</td>\n",
       "      <td>0.874374</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>0.038817</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>0.025459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.072906</td>\n",
       "      <td>4.012825</td>\n",
       "      <td>0.864322</td>\n",
       "      <td>0.867466</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.873585</td>\n",
       "      <td>0.879245</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.821092</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.341218</td>\n",
       "      <td>0.021448</td>\n",
       "      <td>0.035630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.139204</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958647</td>\n",
       "      <td>0.969811</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.958569</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.011588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.091749</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.953517</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>0.956685</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.951036</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.002357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.089401</td>\n",
       "      <td>4.088693</td>\n",
       "      <td>0.947236</td>\n",
       "      <td>0.958544</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.960377</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.962335</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.952919</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.072530</td>\n",
       "      <td>3.948049</td>\n",
       "      <td>0.942211</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</td>\n",
       "      <td>100</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.956685</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.043339</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.006249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.107074</td>\n",
       "      <td>0.067198</td>\n",
       "      <td>0.851759</td>\n",
       "      <td>0.881924</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.769811</td>\n",
       "      <td>0.849341</td>\n",
       "      <td>0.898113</td>\n",
       "      <td>0.890772</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.058062</td>\n",
       "      <td>0.023828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.077430</td>\n",
       "      <td>0.055829</td>\n",
       "      <td>0.863065</td>\n",
       "      <td>0.891341</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.010831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.084263</td>\n",
       "      <td>3.925046</td>\n",
       "      <td>0.851759</td>\n",
       "      <td>0.877550</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.937736</td>\n",
       "      <td>0.747170</td>\n",
       "      <td>0.832392</td>\n",
       "      <td>0.890566</td>\n",
       "      <td>0.862524</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.068516</td>\n",
       "      <td>4.041030</td>\n",
       "      <td>0.851759</td>\n",
       "      <td>0.890727</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.839925</td>\n",
       "      <td>0.916981</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.071872</td>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.037273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.107138</td>\n",
       "      <td>0.055837</td>\n",
       "      <td>0.900754</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.901887</td>\n",
       "      <td>0.919021</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.902072</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.015354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.073236</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.913955</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.930189</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.913371</td>\n",
       "      <td>0.901887</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.022325</td>\n",
       "      <td>0.013023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.086740</td>\n",
       "      <td>3.874635</td>\n",
       "      <td>0.903266</td>\n",
       "      <td>0.917727</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913534</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.901887</td>\n",
       "      <td>0.905838</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.015501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.068367</td>\n",
       "      <td>3.899313</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>0.918354</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.937736</td>\n",
       "      <td>0.883019</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.902072</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.073429</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.119656</td>\n",
       "      <td>0.077034</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.882545</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890977</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.901887</td>\n",
       "      <td>0.877589</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.008375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.087414</td>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.861809</td>\n",
       "      <td>0.885685</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.868173</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.012468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.085567</td>\n",
       "      <td>3.951686</td>\n",
       "      <td>0.810302</td>\n",
       "      <td>0.824758</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853383</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.784906</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.103844</td>\n",
       "      <td>0.030676</td>\n",
       "      <td>0.013023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.074869</td>\n",
       "      <td>3.858196</td>\n",
       "      <td>0.797739</td>\n",
       "      <td>0.822887</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853383</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.758491</td>\n",
       "      <td>0.792844</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.067615</td>\n",
       "      <td>0.040489</td>\n",
       "      <td>0.027087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.083881</td>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.949752</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.954717</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.958569</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.935970</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.009871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.086481</td>\n",
       "      <td>0.076539</td>\n",
       "      <td>0.923367</td>\n",
       "      <td>0.951013</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>word</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.964151</td>\n",
       "      <td>0.928302</td>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>0.009572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.100609</td>\n",
       "      <td>4.028908</td>\n",
       "      <td>0.920854</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913534</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.951036</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.928437</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.161761</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.009226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.079205</td>\n",
       "      <td>4.043104</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.948494</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function lem_rmv_digit at 0x000001DCD144B9D8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.952919</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0   0.597575       0.069352         0.928392         0.937808           \n",
       "1   0.626285       0.082050         0.900754         0.917071           \n",
       "2   9.295043       4.570321         0.915829         0.928400           \n",
       "3   8.286953       4.761483         0.896985         0.900769           \n",
       "4   0.376099       0.082049         0.958543         0.995606           \n",
       "5   0.198426       0.063370         0.958543         0.997487           \n",
       "6   0.256382       4.112712         0.958543         0.994343           \n",
       "7   0.217856       4.202346         0.958543         0.991837           \n",
       "8   0.492947       0.059679         0.878141         0.884443           \n",
       "9   0.428101       0.061174         0.891960         0.893230           \n",
       "10  0.833805       4.401734         0.854271         0.872482           \n",
       "11  0.515058       4.027507         0.836683         0.846734           \n",
       "12  3.302305       0.076215         0.951005         0.974249           \n",
       "13  2.648962       0.073021         0.949749         0.972993           \n",
       "14  3.513599       3.891695         0.951005         0.970476           \n",
       "15  2.558616       3.896018         0.909548         0.941591           \n",
       "16  0.098582       0.057348         0.942211         0.947236           \n",
       "17  0.079571       0.053506         0.938442         0.945353           \n",
       "18  0.081080       3.904082         0.927136         0.929657           \n",
       "19  0.069392       3.867975         0.922111         0.935933           \n",
       "20  0.107295       0.056806         0.967337         0.979901           \n",
       "21  0.090519       0.057491         0.969849         0.979273           \n",
       "22  0.087903       3.926058         0.967337         0.981785           \n",
       "23  0.079876       3.826979         0.962312         0.981158           \n",
       "24  0.107791       0.062165         0.900754         0.910819           \n",
       "25  0.081719       0.057321         0.884422         0.894482           \n",
       "26  0.088081       4.009394         0.850503         0.852397           \n",
       "27  0.075872       3.975829         0.845477         0.848001           \n",
       "28  0.129847       0.111797         0.942211         0.940333           \n",
       "29  0.091746       0.079549         0.942211         0.939697           \n",
       "..       ...            ...              ...              ...           \n",
       "34  0.085080       4.063243         0.932161         0.930286           \n",
       "35  0.069050       4.047359         0.919598         0.939078           \n",
       "36  0.102876       0.056644         0.967337         0.986182           \n",
       "37  0.081628       0.057046         0.968593         0.990577           \n",
       "38  0.097791       3.981878         0.971106         0.989951           \n",
       "39  0.076161       4.065263         0.967337         0.988068           \n",
       "40  0.096262       0.060995         0.898241         0.918353           \n",
       "41  0.085731       0.069687         0.891960         0.900763           \n",
       "42  0.096927       4.171902         0.875628         0.874374           \n",
       "43  0.072906       4.012825         0.864322         0.867466           \n",
       "44  0.139204       0.095089         0.954774         0.956667           \n",
       "45  0.091749       0.081146         0.945980         0.953517           \n",
       "46  0.089401       4.088693         0.947236         0.958544           \n",
       "47  0.072530       3.948049         0.942211         0.957910           \n",
       "48  0.107074       0.067198         0.851759         0.881924           \n",
       "49  0.077430       0.055829         0.863065         0.891341           \n",
       "50  0.084263       3.925046         0.851759         0.877550           \n",
       "51  0.068516       4.041030         0.851759         0.890727           \n",
       "52  0.107138       0.055837         0.900754         0.920238           \n",
       "53  0.073236       0.052135         0.894472         0.913955           \n",
       "54  0.086740       3.874635         0.903266         0.917727           \n",
       "55  0.068367       3.899313         0.904523         0.918354           \n",
       "56  0.119656       0.077034         0.876884         0.882545           \n",
       "57  0.087414       0.061833         0.861809         0.885685           \n",
       "58  0.085567       3.951686         0.810302         0.824758           \n",
       "59  0.074869       3.858196         0.797739         0.822887           \n",
       "60  0.105957       0.083881         0.949749         0.949752           \n",
       "61  0.086481       0.076539         0.923367         0.951013           \n",
       "62  0.100609       4.028908         0.920854         0.939698           \n",
       "63  0.079205       4.043104         0.919598         0.948494           \n",
       "\n",
       "                                                                                                                                                                                                                                                                      param_clf  \\\n",
       "0   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "1   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "2   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "3   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "4   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "5   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "6   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "7   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "8   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "9   LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "10  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "11  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "12  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "13  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "14  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "15  LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\\n     verbose=0)                                                    \n",
       "16  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "17  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "18  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "19  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "20  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "21  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "22  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "23  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "24  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "25  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "26  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "27  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "28  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "29  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "..                                                                                                                                                                                                                                                                          ...   \n",
       "34  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "35  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "36  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "37  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "38  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "39  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "40  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "41  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "42  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "43  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "44  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "45  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "46  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "47  LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)   \n",
       "48  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "49  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "50  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "51  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "52  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "53  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "54  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "55  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "56  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "57  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "58  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "59  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "60  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "61  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "62  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "63  GaussianNB(priors=None)                                                                                                                                                                                                                                                       \n",
       "\n",
       "   param_clf__C  \\\n",
       "0   1000          \n",
       "1   1000          \n",
       "2   1000          \n",
       "3   1000          \n",
       "4   1000          \n",
       "5   1000          \n",
       "6   1000          \n",
       "7   1000          \n",
       "8   1000          \n",
       "9   1000          \n",
       "10  1000          \n",
       "11  1000          \n",
       "12  1000          \n",
       "13  1000          \n",
       "14  1000          \n",
       "15  1000          \n",
       "16  10            \n",
       "17  10            \n",
       "18  10            \n",
       "19  10            \n",
       "20  10            \n",
       "21  10            \n",
       "22  10            \n",
       "23  10            \n",
       "24  10            \n",
       "25  10            \n",
       "26  10            \n",
       "27  10            \n",
       "28  10            \n",
       "29  10            \n",
       "..  ..            \n",
       "34  100           \n",
       "35  100           \n",
       "36  100           \n",
       "37  100           \n",
       "38  100           \n",
       "39  100           \n",
       "40  100           \n",
       "41  100           \n",
       "42  100           \n",
       "43  100           \n",
       "44  100           \n",
       "45  100           \n",
       "46  100           \n",
       "47  100           \n",
       "48  NaN           \n",
       "49  NaN           \n",
       "50  NaN           \n",
       "51  NaN           \n",
       "52  NaN           \n",
       "53  NaN           \n",
       "54  NaN           \n",
       "55  NaN           \n",
       "56  NaN           \n",
       "57  NaN           \n",
       "58  NaN           \n",
       "59  NaN           \n",
       "60  NaN           \n",
       "61  NaN           \n",
       "62  NaN           \n",
       "63  NaN           \n",
       "\n",
       "                                                                                                                                                             param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "1   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "2   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "3   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "4   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "5   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "6   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "7   TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "8   NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "9   NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "10  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "11  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "12  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "13  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "16  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "17  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "18  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "19  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "20  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "21  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "22  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "23  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "24  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "25  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "26  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "27  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "28  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "29  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "..                                                                                                                                                                        ...   \n",
       "34  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "35  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "36  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "37  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "38  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "39  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "40  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "41  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "42  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "43  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "44  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "45  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "46  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "47  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "48  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "49  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "50  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "51  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "52  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "53  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "54  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "55  TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\\n       random_state=None, tol=0.0)                                                                         \n",
       "56  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "57  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "58  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "59  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "60  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "61  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "62  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "63  NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\\n  n_components=50, random_state=None, shuffle=False, solver='cd',\\n  tol=0.0001, verbose=0)   \n",
       "\n",
       "   param_reduce_dim__n_components  \\\n",
       "0   10                              \n",
       "1   10                              \n",
       "2   10                              \n",
       "3   10                              \n",
       "4   50                              \n",
       "5   50                              \n",
       "6   50                              \n",
       "7   50                              \n",
       "8   10                              \n",
       "9   10                              \n",
       "10  10                              \n",
       "11  10                              \n",
       "12  50                              \n",
       "13  50                              \n",
       "14  50                              \n",
       "15  50                              \n",
       "16  10                              \n",
       "17  10                              \n",
       "18  10                              \n",
       "19  10                              \n",
       "20  50                              \n",
       "21  50                              \n",
       "22  50                              \n",
       "23  50                              \n",
       "24  10                              \n",
       "25  10                              \n",
       "26  10                              \n",
       "27  10                              \n",
       "28  50                              \n",
       "29  50                              \n",
       "..  ..                              \n",
       "34  10                              \n",
       "35  10                              \n",
       "36  50                              \n",
       "37  50                              \n",
       "38  50                              \n",
       "39  50                              \n",
       "40  10                              \n",
       "41  10                              \n",
       "42  10                              \n",
       "43  10                              \n",
       "44  50                              \n",
       "45  50                              \n",
       "46  50                              \n",
       "47  50                              \n",
       "48  10                              \n",
       "49  10                              \n",
       "50  10                              \n",
       "51  10                              \n",
       "52  50                              \n",
       "53  50                              \n",
       "54  50                              \n",
       "55  50                              \n",
       "56  10                              \n",
       "57  10                              \n",
       "58  10                              \n",
       "59  10                              \n",
       "60  50                              \n",
       "61  50                              \n",
       "62  50                              \n",
       "63  50                              \n",
       "\n",
       "                              param_vect__analyzer param_vect__min_df  \\\n",
       "0   word                                            3                   \n",
       "1   word                                            5                   \n",
       "2   <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "3   <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "4   word                                            3                   \n",
       "5   word                                            5                   \n",
       "6   <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "7   <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "8   word                                            3                   \n",
       "9   word                                            5                   \n",
       "10  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "11  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "12  word                                            3                   \n",
       "13  word                                            5                   \n",
       "14  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "15  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "16  word                                            3                   \n",
       "17  word                                            5                   \n",
       "18  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "19  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "20  word                                            3                   \n",
       "21  word                                            5                   \n",
       "22  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "23  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "24  word                                            3                   \n",
       "25  word                                            5                   \n",
       "26  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "27  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "28  word                                            3                   \n",
       "29  word                                            5                   \n",
       "..   ...                                           ..                   \n",
       "34  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "35  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "36  word                                            3                   \n",
       "37  word                                            5                   \n",
       "38  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "39  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "40  word                                            3                   \n",
       "41  word                                            5                   \n",
       "42  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "43  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "44  word                                            3                   \n",
       "45  word                                            5                   \n",
       "46  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "47  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "48  word                                            3                   \n",
       "49  word                                            5                   \n",
       "50  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "51  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "52  word                                            3                   \n",
       "53  word                                            5                   \n",
       "54  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "55  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "56  word                                            3                   \n",
       "57  word                                            5                   \n",
       "58  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "59  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "60  word                                            3                   \n",
       "61  word                                            5                   \n",
       "62  <function lem_rmv_digit at 0x000001DCD144B9D8>  3                   \n",
       "63  <function lem_rmv_digit at 0x000001DCD144B9D8>  5                   \n",
       "\n",
       "         ...        split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0        ...         0.902256          0.928302            0.932075            \n",
       "1        ...         0.864662          0.894340            0.879245            \n",
       "2        ...         0.913534          0.941509            0.905660            \n",
       "3        ...         0.906015          0.924528            0.833962            \n",
       "4        ...         0.954887          1.000000            0.947170            \n",
       "5        ...         0.939850          0.996226            0.958491            \n",
       "6        ...         0.947368          0.988679            0.954717            \n",
       "7        ...         0.962406          0.996226            0.962264            \n",
       "8        ...         0.902256          0.916981            0.822642            \n",
       "9        ...         0.879699          0.915094            0.883019            \n",
       "10       ...         0.868421          0.864151            0.871698            \n",
       "11       ...         0.845865          0.847170            0.875472            \n",
       "12       ...         0.951128          0.979245            0.943396            \n",
       "13       ...         0.947368          0.977358            0.932075            \n",
       "14       ...         0.954887          0.967925            0.943396            \n",
       "15       ...         0.924812          0.954717            0.867925            \n",
       "16       ...         0.921053          0.947170            0.935849            \n",
       "17       ...         0.921053          0.947170            0.932075            \n",
       "18       ...         0.921053          0.943396            0.909434            \n",
       "19       ...         0.917293          0.941509            0.901887            \n",
       "20       ...         0.951128          0.983019            0.966038            \n",
       "21       ...         0.954887          0.981132            0.966038            \n",
       "22       ...         0.947368          0.983019            0.966038            \n",
       "23       ...         0.939850          0.984906            0.962264            \n",
       "24       ...         0.898496          0.933962            0.867925            \n",
       "25       ...         0.890977          0.909434            0.867925            \n",
       "26       ...         0.872180          0.867925            0.852830            \n",
       "27       ...         0.860902          0.866038            0.871698            \n",
       "28       ...         0.954887          0.950943            0.939623            \n",
       "29       ...         0.932331          0.937736            0.947170            \n",
       "..       ...              ...               ...                 ...            \n",
       "34       ...         0.932331          0.945283            0.913208            \n",
       "35       ...         0.913534          0.950943            0.894340            \n",
       "36       ...         0.958647          0.988679            0.958491            \n",
       "37       ...         0.958647          0.988679            0.958491            \n",
       "38       ...         0.962406          0.992453            0.962264            \n",
       "39       ...         0.958647          0.992453            0.962264            \n",
       "40       ...         0.906015          0.935849            0.864151            \n",
       "41       ...         0.883459          0.915094            0.886792            \n",
       "42       ...         0.898496          0.877358            0.875472            \n",
       "43       ...         0.879699          0.873585            0.879245            \n",
       "44       ...         0.958647          0.969811            0.939623            \n",
       "45       ...         0.932331          0.952830            0.954717            \n",
       "46       ...         0.939850          0.960377            0.950943            \n",
       "47       ...         0.928571          0.950943            0.932075            \n",
       "48       ...         0.887218          0.905660            0.769811            \n",
       "49       ...         0.887218          0.905660            0.815094            \n",
       "50       ...         0.917293          0.937736            0.747170            \n",
       "51       ...         0.887218          0.928302            0.750943            \n",
       "52       ...         0.906015          0.939623            0.901887            \n",
       "53       ...         0.917293          0.930189            0.864151            \n",
       "54       ...         0.913534          0.939623            0.894340            \n",
       "55       ...         0.917293          0.937736            0.883019            \n",
       "56       ...         0.890977          0.894340            0.837736            \n",
       "57       ...         0.868421          0.896226            0.841509            \n",
       "58       ...         0.853383          0.839623            0.792453            \n",
       "59       ...         0.853383          0.858491            0.781132            \n",
       "60       ...         0.947368          0.954717            0.950943            \n",
       "61       ...         0.902256          0.964151            0.928302            \n",
       "62       ...         0.913534          0.939623            0.924528            \n",
       "63       ...         0.906015          0.950943            0.913208            \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0   0.956685            0.950943           0.928437            0.052436       \n",
       "1   0.924670            0.958491           0.932203            0.014957       \n",
       "2   0.943503            0.928302           0.900188            0.393938       \n",
       "3   0.851224            0.950943           0.926554            0.219834       \n",
       "4   0.988701            0.973585           0.998117            0.024337       \n",
       "5   0.998117            0.977358           0.998117            0.004180       \n",
       "6   1.000000            0.973585           0.994350            0.013699       \n",
       "7   0.998117            0.950943           0.981168            0.009846       \n",
       "8   0.838041            0.909434           0.898305            0.155257       \n",
       "9   0.892655            0.913208           0.871940            0.071626       \n",
       "10  0.919021            0.822642           0.834275            0.109942       \n",
       "11  0.909605            0.788679           0.783427            0.090366       \n",
       "12  0.979284            0.958491           0.964218            0.854412       \n",
       "13  0.975518            0.969811           0.966102            0.261044       \n",
       "14  0.975518            0.954717           0.967985            0.420537       \n",
       "15  0.907721            0.935849           0.962335            0.366181       \n",
       "16  0.952919            0.969811           0.941620            0.002544       \n",
       "17  0.951036            0.962264           0.937853            0.000937       \n",
       "18  0.941620            0.950943           0.903955            0.001181       \n",
       "19  0.935970            0.947170           0.930320            0.003462       \n",
       "20  0.979284            0.984906           0.977401            0.009931       \n",
       "21  0.977401            0.988679           0.979284            0.002695       \n",
       "22  0.984934            0.988679           0.977401            0.001249       \n",
       "23  0.981168            0.984906           0.977401            0.009493       \n",
       "24  0.900188            0.935849           0.898305            0.004313       \n",
       "25  0.894539            0.894340           0.879473            0.002490       \n",
       "26  0.881356            0.826415           0.807910            0.005577       \n",
       "27  0.887006            0.803774           0.790960            0.002099       \n",
       "28  0.947269            0.932075           0.922787            0.011033       \n",
       "29  0.945386            0.947170           0.935970            0.013571       \n",
       "..       ...                 ...                ...                 ...       \n",
       "34  0.943503            0.950943           0.902072            0.004880       \n",
       "35  0.935970            0.950943           0.930320            0.000608       \n",
       "36  0.984934            0.984906           0.984934            0.004380       \n",
       "37  0.990584            0.988679           0.992467            0.002291       \n",
       "38  0.986817            0.988679           0.990584            0.002286       \n",
       "39  0.984934            0.981132           0.986817            0.002998       \n",
       "40  0.909605            0.924528           0.909605            0.003570       \n",
       "41  0.907721            0.905660           0.879473            0.002489       \n",
       "42  0.903955            0.852830           0.841808            0.013922       \n",
       "43  0.907721            0.833962           0.821092            0.003931       \n",
       "44  0.958569            0.966038           0.941620            0.005735       \n",
       "45  0.956685            0.950943           0.951036            0.006137       \n",
       "46  0.962335            0.950943           0.952919            0.003489       \n",
       "47  0.956685            0.966038           0.966102            0.002062       \n",
       "48  0.849341            0.898113           0.890772            0.009777       \n",
       "49  0.879473            0.886792           0.888889            0.001650       \n",
       "50  0.832392            0.890566           0.862524            0.002864       \n",
       "51  0.839925            0.916981           0.903955            0.000490       \n",
       "52  0.919021            0.894340           0.902072            0.019785       \n",
       "53  0.913371            0.901887           0.898305            0.001456       \n",
       "54  0.907721            0.901887           0.905838            0.007605       \n",
       "55  0.915254            0.913208           0.902072            0.001863       \n",
       "56  0.875706            0.901887           0.877589            0.018610       \n",
       "57  0.892655            0.875472           0.868173            0.010878       \n",
       "58  0.826742            0.784906           0.807910            0.006198       \n",
       "59  0.817326            0.758491           0.792844            0.002499       \n",
       "60  0.958569            0.950943           0.935970            0.003874       \n",
       "61  0.947269            0.939623           0.941620            0.002620       \n",
       "62  0.951036            0.924528           0.928437            0.024590       \n",
       "63  0.952919            0.939623           0.941620            0.008627       \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0   0.014782        0.020052        0.013348         \n",
       "1   0.019341        0.041220        0.016365         \n",
       "2   0.554896        0.009380        0.019965         \n",
       "3   0.993047        0.048154        0.035043         \n",
       "4   0.032748        0.011084        0.004943         \n",
       "5   0.003849        0.015318        0.000891         \n",
       "6   0.174841        0.011042        0.004622         \n",
       "7   0.169242        0.005369        0.007584         \n",
       "8   0.002135        0.039316        0.033685         \n",
       "9   0.002947        0.015071        0.017622         \n",
       "10  0.129658        0.022385        0.035095         \n",
       "11  0.149148        0.036003        0.051512         \n",
       "12  0.002458        0.006159        0.007093         \n",
       "13  0.002394        0.015488        0.004930         \n",
       "14  0.078187        0.005376        0.003565         \n",
       "15  0.013827        0.029748        0.024151         \n",
       "16  0.005535        0.020413        0.004613         \n",
       "17  0.001232        0.017420        0.005533         \n",
       "18  0.201066        0.017475        0.018189         \n",
       "19  0.083538        0.018788        0.004568         \n",
       "20  0.001327        0.013825        0.002335         \n",
       "21  0.002364        0.014060        0.001523         \n",
       "22  0.151158        0.016895        0.003197         \n",
       "23  0.069792        0.018400        0.003064         \n",
       "24  0.003752        0.027759        0.016383         \n",
       "25  0.001314        0.011735        0.012232         \n",
       "26  0.110744        0.018762        0.031931         \n",
       "27  0.119753        0.029789        0.041232         \n",
       "28  0.005773        0.009494        0.012497         \n",
       "29  0.002874        0.007000        0.004087         \n",
       "..       ...             ...             ...         \n",
       "34  0.166909        0.015396        0.019964         \n",
       "35  0.259064        0.023490        0.008701         \n",
       "36  0.001216        0.012412        0.001765         \n",
       "37  0.000948        0.014190        0.001546         \n",
       "38  0.083380        0.012415        0.002344         \n",
       "39  0.067521        0.009857        0.003194         \n",
       "40  0.002467        0.025242        0.012372         \n",
       "41  0.010668        0.009774        0.015352         \n",
       "42  0.038817        0.018649        0.025459         \n",
       "43  0.341218        0.021448        0.035630         \n",
       "44  0.003480        0.011121        0.011588         \n",
       "45  0.004307        0.009791        0.002357         \n",
       "46  0.024192        0.005233        0.004057         \n",
       "47  0.043339        0.016893        0.006249         \n",
       "48  0.003092        0.058062        0.023828         \n",
       "49  0.002642        0.033889        0.010831         \n",
       "50  0.091231        0.074688        0.044300         \n",
       "51  0.071872        0.072250        0.037273         \n",
       "52  0.002499        0.004835        0.015354         \n",
       "53  0.001641        0.022325        0.013023         \n",
       "54  0.124883        0.007899        0.015501         \n",
       "55  0.073429        0.015282        0.014724         \n",
       "56  0.013556        0.028013        0.008375         \n",
       "57  0.007058        0.014627        0.012468         \n",
       "58  0.103844        0.030676        0.013023         \n",
       "59  0.067615        0.040489        0.027087         \n",
       "60  0.006188        0.001686        0.009871         \n",
       "61  0.001896        0.015653        0.009572         \n",
       "62  0.161761        0.005186        0.009226         \n",
       "63  0.122591        0.014448        0.004927         \n",
       "\n",
       "[64 rows x 22 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(grid.cv_results_) # With headers and footers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
